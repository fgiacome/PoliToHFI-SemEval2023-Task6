{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T17:16:52.239356Z","iopub.status.busy":"2024-02-22T17:16:52.238982Z","iopub.status.idle":"2024-02-22T17:16:52.244815Z","shell.execute_reply":"2024-02-22T17:16:52.243749Z","shell.execute_reply.started":"2024-02-22T17:16:52.239328Z"},"trusted":true},"outputs":[],"source":["import torch\n","import json\n","from torch.utils.data import Dataset\n","import numpy as np\n","from transformers import AutoTokenizer, RobertaTokenizerFast"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T17:16:52.246542Z","iopub.status.busy":"2024-02-22T17:16:52.246269Z","iopub.status.idle":"2024-02-22T17:16:52.255852Z","shell.execute_reply":"2024-02-22T17:16:52.255032Z","shell.execute_reply.started":"2024-02-22T17:16:52.246519Z"},"trusted":true},"outputs":[],"source":["all_questions = {\n","    \"COURT\": \"Which court is mentioned in the text?\",\n","    \"DATE\": \"What is the date mentioned in the text?\",\n","    # \"PETITIONER\": \"Who is the petitioner mentioned in the text?\",\n","    # \"RESPONDENT\": \"Who is the respondent mentioned in the text?\",\n","    \"JUDGE\": \"Who is the judge mentioned in the text?\",\n","    # \"ORG\": \"What organization is mentioned in the text?\",\n","    # \"GPE\": \"What geopolitical entity is mentioned in the text?\",\n","    # \"STATUTE\": \"What statute is mentioned in the text?\",\n","    # \"PROVISION\": \"What provision is mentioned in the text?\",\n","    # \"PRECEDENT\": \"What precedent is mentioned in the text?\",\n","    # \"CASE_NUMBER\": \"What is the case number mentioned in the text?\",\n","    # \"WITNESS\": \"Who is the witness mentioned in the text?\",\n","    # \"OTHER_PERSON\": \"Who is the other person mentioned in the text?\",\n","    # \"LAWYER\": \"Who is the lawyer mentioned in the text?\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T17:16:52.257760Z","iopub.status.busy":"2024-02-22T17:16:52.257525Z","iopub.status.idle":"2024-02-22T17:16:52.271999Z","shell.execute_reply":"2024-02-22T17:16:52.271175Z","shell.execute_reply.started":"2024-02-22T17:16:52.257741Z"},"trusted":true},"outputs":[],"source":["class LegalQADataSet:\n","    def __init__(self, dataset_path):\n","        self.data = json.load(open(dataset_path))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        text = item[\"data\"][\"text\"]\n","\n","        qa_pairs = []\n","        # generate all\n","        for tag, question in all_questions.items():\n","            qa_pair = {\"context\": text, \"question\": question, \"tag\": tag}\n","            qa_pairs.append(qa_pair)\n","\n","        # Generate a question-answer pair from annotations\n","        labels = []\n","        for annotation in item[\"annotations\"][0][\"result\"]:\n","            label = annotation[\"value\"][\"labels\"][0]\n","            answer_start = annotation[\"value\"][\"start\"]\n","            answer_end = annotation[\"value\"][\"end\"]\n","            if label in all_questions.keys():\n","                labels.append(\n","                    {\"label\": label, \"start\": answer_start, \"end\": answer_end}\n","                )\n","\n","        return {\"qa_pairs\": qa_pairs, \"labels\": labels}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T17:16:52.273827Z","iopub.status.busy":"2024-02-22T17:16:52.273245Z","iopub.status.idle":"2024-02-22T17:16:52.978430Z","shell.execute_reply":"2024-02-22T17:16:52.977418Z","shell.execute_reply.started":"2024-02-22T17:16:52.273796Z"},"trusted":true},"outputs":[],"source":["from transformers import pipeline\n","import torch\n","\n","# Create a QA pipeline\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","qa_pipeline = pipeline(\n","    \"question-answering\", model=\"deepset/roberta-base-squad2\", device=device\n",")  # 指定device=0表示使用第一个GPU\n","\n","dataset_path = (\n","    \"/kaggle/working/NER_DEV/NER_DEV/NER_DEV_ALL.json\"\n",")\n","dataset = LegalQADataSet(dataset_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-22T17:17:14.115519Z","iopub.status.busy":"2024-02-22T17:17:14.115159Z"},"trusted":true},"outputs":[],"source":["import torch\n","from sklearn.metrics import f1_score\n","from tqdm import tqdm\n","\n","\n","# Store real and predicted labels\n","true_labels = []\n","predicted_labels = []\n","\n","\n","# Use pipeline for inference and record predicted labels\n","for sample in tqdm(dataset):\n","    # For each QA pair, get the context, question, and ground truth label\n","    true_labels.append(sample[\"labels\"])\n","    output_labels = []\n","    for qa_pair in sample[\"qa_pairs\"]:\n","        context = qa_pair[\"context\"]\n","        question = qa_pair[\"question\"]\n","        tag = qa_pair[\"tag\"]\n","\n","        # print(question)\n","\n","        # use pipeline to predict\n","        qa_input = {\"question\": question, \"context\": context}\n","        qa_output = qa_pipeline(qa_input)\n","        ans_confidence = qa_output[\"score\"]\n","        if ans_confidence >= 0.2:\n","            output_label = {\n","                \"label\": tag,\n","                \"start\": qa_output[\"start\"],\n","                \"end\": qa_output[\"end\"],\n","            }\n","            output_labels.append(output_label)\n","    predicted_labels.append(output_labels)\n","\n","results = [\n","    {\"predicted\": p_l, \"true\": t_l} for p_l, t_l in zip(predicted_labels, true_labels)\n","]\n","\n","with open(\"qa_ner.json\", \"w\") as fp:\n","    json.dump(results, fp)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from nervaluate import Evaluator\n","\n","evaluator = Evaluator(true_labels, predicted_labels, tags=all_questions.keys())\n","results, results_per_tag = evaluator.evaluate()\n","\n","with open(\"qa_ner_evaluation.json\", \"w\") as fp:\n","    json.dump([results, results_per_tag], fp)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4124852,"sourceId":7145674,"sourceType":"datasetVersion"},{"datasetId":4460000,"sourceId":7650597,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
